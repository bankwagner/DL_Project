unet - ~290 MB
- training: batch_size 8, learning_rate 0.0001, epochs 30 --> takes about 15 mins
- evaluation: Mean IoU = 0.8295, Mean F1 Score = 0.9459
- chatgpt: UNet is a convolutional neural network (CNN) architecture commonly used for image segmentation tasks. It was introduced by Olaf Ronneberger, Philipp Fischer, and Thomas Brox in 2015. The name "UNet" comes from its U-shaped architecture.

Here are the key features of the UNet architecture:

Encoder-Decoder Structure: UNet consists of two main parts: an encoder and a decoder. The encoder is responsible for capturing the contextual information from the input image, while the decoder is responsible for spatial localization.

Contracting Path (Encoder): The encoder is designed as a series of convolutional and pooling layers that progressively reduce the spatial resolution of the input image while increasing the depth of features. This is sometimes referred to as the "contracting path" because it compresses the input information into a more abstract representation.

Expansive Path (Decoder): The decoder, or expansive path, is designed to upsample the feature map to the original input resolution. It uses transposed convolutions (also known as deconvolutions or upsampling) to gradually recover the spatial information.

Skip Connections: One notable feature of UNet is the use of skip connections. Skip connections connect corresponding layers between the encoder and decoder. These connections allow the network to retain high-resolution information during the upsampling process, helping to improve segmentation performance.

Final Convolutional Layer: The architecture typically ends with a final convolutional layer that produces the segmentation mask. This layer usually has a number of output channels equal to the number of classes in the segmentation task.

UNet is widely used in medical image segmentation, such as segmenting organs or lesions in medical scans. Its architecture has been found to be effective in capturing both local and global features, and the skip connections help in preserving fine details during the upsampling process. Various modifications and improvements to the original UNet architecture have been proposed over time to address specific challenges in different segmentation tasks.








linknet - ~250 MB
- training: batch_size 8, learning_rate 0.0001, epochs 30 --> takes about 15 mins
- evaluation: Mean IoU = 0.8170, Mean F1 Score = 0.9405
- chatgpt: LinkNet is another convolutional neural network (CNN) architecture designed for image segmentation tasks. It was proposed by Alexander G. Buslaev, Alexey I. Zhidkov, Valentin V. Iglovikov, and Alexey A. Shvets in 2017. Similar to UNet, LinkNet is used for semantic segmentation, where the goal is to assign a label to each pixel in an input image.

Here are some key features of the LinkNet architecture:

Encoder-Decoder Architecture: LinkNet, like UNet, follows an encoder-decoder structure. The encoder is responsible for extracting features from the input image, and the decoder is responsible for generating the segmentation mask.

Skip Connections with Link Modules: One of the distinctive features of LinkNet is the use of link modules, which are skip connections with residual connections. These links connect corresponding layers between the encoder and decoder, similar to skip connections in UNet. However, in LinkNet, residual connections are incorporated into the links to facilitate smoother information flow.

Residual Blocks in Encoder: LinkNet utilizes residual blocks in the encoder, which are inspired by the residual networks (ResNet) architecture. Residual blocks help address the vanishing gradient problem, allowing the network to train more effectively, especially when dealing with deep architectures.

Spatial Attention Module: LinkNet includes a spatial attention module, which helps the network focus on more relevant parts of the input image during the segmentation process. This attention mechanism aids in capturing long-range dependencies in the image.

Batch Normalization: Batch normalization is used throughout the network to normalize activations and accelerate training. This normalization technique helps with the stability and speed of convergence during the training process.

LinkNet has been applied to various segmentation tasks, including medical image segmentation and object detection. Its modular design, use of skip connections with residual connections, and attention mechanisms contribute to its effectiveness in capturing both local and global contextual information in images. The combination of these features helps improve segmentation accuracy, particularly in cases where capturing fine details and preserving spatial relationships are crucial.






fpn - ~280 MB
- training: batch_size 8, learning_rate 0.0001, epochs 20 --> takes about 20 mins
- evaluation: Mean IoU = 0.8225, Mean F1 Score = 0.9396
- chatgpt: Feature Pyramid Network (FPN) is another popular convolutional neural network (CNN) architecture, particularly used for object detection tasks. FPN was introduced by Tsung-Yi Lin, Piotr Dollar, Ross Girshick, Kaiming He, Bharath Hariharan in a paper titled "Feature Pyramid Networks for Object Detection," published in 2017.

Here are the key features of the Feature Pyramid Network (FPN) architecture:

Multi-scale Feature Pyramid: FPN addresses the challenge of object detection at multiple scales by creating a feature pyramid. The pyramid consists of feature maps at different spatial resolutions, allowing the network to capture information at various scales. This is crucial for detecting objects of different sizes in an image.

Bottom-up and Top-down Architecture: FPN combines a bottom-up pathway (similar to a standard convolutional network) with a top-down pathway. The bottom-up pathway involves the typical convolutional layers that extract high-level features from the input image. The top-down pathway involves upsampling and merging high-resolution features from the lower levels of the pyramid to the higher levels, enhancing the network's ability to detect objects at different scales.

Feature Fusion: FPN incorporates feature fusion to combine information from different levels of the pyramid. This fusion is achieved by adding feature maps from the top-down pathway to the corresponding feature maps from the bottom-up pathway. The fusion helps improve the localization of objects across various scales.

Pyramid Pooling: FPN uses a technique called pyramid pooling to pool features at multiple scales. This involves pooling features from different pyramid levels and concatenating them, providing a more comprehensive representation of the image.

Object Detection Heads: FPN is often used in conjunction with object detection frameworks, such as Faster R-CNN. The multi-scale feature pyramid is connected to the Region Proposal Network (RPN) and the object detection heads, facilitating the generation of region proposals and the final object detections.

FPN has proven effective in improving the performance of object detection models, especially in scenarios where objects have varying sizes. It has become a standard component in many state-of-the-art object detection architectures.





losses
dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25]))
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)
röviden: dice lossnál egyenlő súlyokkal az osztályok, focal lossnál meg a class imbalance-t próblája kiegyenlíteni

DICE loss, also known as Sørensen-Dice coefficient or F1 score, is a metric commonly used in image segmentation tasks to evaluate the performance of a model. It measures the similarity between the predicted segmentation (output) and the ground truth segmentation (target).
The DICE coefficient is defined as:
DICE= 2×∣X∩Y∣ / ∣X∣+∣Y∣
where:
X is the set of pixels predicted as part of the segmentation by the model.
Y is the set of pixels that are actually part of the true segmentation (ground truth).
∣⋅∣ represents the cardinality of a set, i.e., the number of elements in the set.
In the context of image segmentation, the DICE coefficient measures the overlap between the predicted and true segmentations. The coefficient ranges from 0 to 1, where 0 indicates no overlap (complete mismatch) and 1 indicates perfect overlap (perfect match).
The DICE loss is then derived from the DICE coefficient to be used as a loss function during the training of segmentation models. The DICE loss is simply 
1−DICE, so that minimizing this loss during training corresponds to maximizing the DICE coefficient.
In summary, DICE loss is a measure of dissimilarity between predicted and true segmentations in image segmentation tasks, and it is commonly used as a loss function to train models that perform segmentation.


Focal Loss is a loss function introduced by Lin et al. in the paper titled "Focal Loss for Dense Object Detection" (2017). It was primarily designed to address the issue of class imbalance in object detection tasks, where the number of background (non-object) samples far outweighs the number of foreground (object) samples. However, the Focal Loss has since been applied to various other tasks, including image segmentation.

The main idea behind Focal Loss is to down-weight the contribution of well-classified examples, focusing more on the hard, misclassified examples during training. This is achieved by introducing a modulating factor called the "focusing parameter" (γ) into the standard cross-entropy loss
...
In summary, Focal Loss is a modification of the standard cross-entropy loss, designed to give more emphasis to hard-to-classify examples in the presence of class imbalance. It has been particularly successful in improving the performance of object detection models and has found applications in other tasks as well.

