{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file does: \n",
    "1. environment setup\n",
    "2. loading the data\n",
    "3. reorienting + resizing\n",
    "4. noise removal + smoothing\n",
    "5. normalizing + standardizing\n",
    "6. adjusting brightness + adjusting contrast + adjusting sharpness\n",
    "7. thresholding\n",
    "8. resampling\n",
    "9. data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nilearn\n",
    "#!pip install dicom2nifti\n",
    "#!pip install scikit-image\n",
    "#!pip install requests\n",
    "\n",
    "import dicom2nifti\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import statistics\n",
    "import skimage.transform as skTrans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'D:\\BME\\MSc\\dl-project\\ACDC\\database'\n",
    "start_patient_id = 1\n",
    "end_patient_id = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "└── dl-project\n",
    "    └── ACDC\n",
    "        └── database\n",
    "            ├── patient001\n",
    "            ├── ...\n",
    "            └── patient150\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize every filepath in a given range of patients into a list\n",
    "\n",
    "def get_image_paths(data_path, start_patient_id, end_patient_id):\n",
    "\n",
    "    paths = []\n",
    "\n",
    "    for current_patient_id in range(start_patient_id, end_patient_id + 1):\n",
    "        \n",
    "        current_patient = {\n",
    "            'start_frame': None,\n",
    "            'start_frame_gt': None,\n",
    "            'end_frame': None,\n",
    "            'end_frame_gt': None\n",
    "        }\n",
    "        \n",
    "        current_patient_folder = os.listdir(f'{data_path}\\patient{str(current_patient_id).zfill(3)}')\n",
    "\n",
    "        for file in current_patient_folder:\n",
    "            taken = False\n",
    "            if \"_frame01\" in file and not \"_gt.nii.gz\" in file and not taken:\n",
    "                current_patient['start_frame'] = os.path.join(f'{data_path}\\patient{str(current_patient_id).zfill(3)}', file)\n",
    "                taken = True\n",
    "            elif \"_frame01\" in file and \"_gt.nii.gz\" in file and not taken:\n",
    "                current_patient['start_frame_gt'] = os.path.join(f'{data_path}\\patient{str(current_patient_id).zfill(3)}', file)\n",
    "                taken = True\n",
    "            elif \".nii.gz\" in file and not \"_gt.nii.gz\" in file and not taken:\n",
    "                current_patient['end_frame'] = os.path.join(f'{data_path}\\patient{str(current_patient_id).zfill(3)}', file)\n",
    "                taken = True\n",
    "            elif \"_gt.nii.gz\" in file and not taken:\n",
    "                current_patient['end_frame_gt'] = os.path.join(f'{data_path}\\patient{str(current_patient_id).zfill(3)}', file)\n",
    "                taken = True\n",
    "            elif not \".cfg\" in file and not \"CITATION\" in file and not \"4d\" in file:\n",
    "                print(f'Something went wrong for: {file}')\n",
    "    \n",
    "        paths.append(current_patient)\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "image_paths = get_image_paths(data_path, start_patient_id, end_patient_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(image_paths))\n",
    "# print(type(image_paths))\n",
    "# print(image_paths.index(\"???\"))\n",
    "\n",
    "# os.listdir(os.path.join(f'{data_path}\\patient{str(90).zfill(3)}'))\n",
    "# print(nib.load(image_paths[89][\"start_frame_gt\"]).get_fdata())\n",
    "# for i in image_paths:\n",
    "#     print(i)\n",
    "    # if i[\"start_frame\"] is None:\n",
    "    #     print(\"start_frame is None:\")\n",
    "    # elif i[\"start_frame_gt\"] is None:\n",
    "    #     print(\"start_frame_gt is None:\")\n",
    "    # elif i[\"end_frame\"] is None:\n",
    "    #     print(\"end_frame is None:\")\n",
    "    # elif i[\"end_frame_gt\"] is None:\n",
    "    #     print(\"end_frame_gt is None:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into a list of dicts of 4 elements\n",
    "\n",
    "def load_images(image_paths):\n",
    "    loaded_images = []\n",
    "    for i in image_paths:\n",
    "        loaded_images_of_patient = {\n",
    "            'start_frame': nib.load(i[\"start_frame\"]).get_fdata(),\n",
    "            'start_frame_gt': nib.load(i[\"start_frame_gt\"]).get_fdata(),\n",
    "            'end_frame': nib.load(i[\"end_frame\"]).get_fdata(),\n",
    "            'end_frame_gt': nib.load(i[\"end_frame_gt\"]).get_fdata()\n",
    "        }\n",
    "        loaded_images.append(loaded_images_of_patient)\n",
    "    return loaded_images\n",
    "\n",
    "loaded_images = load_images(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loaded_images[4][\"end_frame_gt\"][:,:,0][156][154])\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(1, 2, 1)  # First subplot\n",
    "\n",
    "# loaded_images[4][\"end_frame_gt\"][:, :, 2][loaded_images[4][\"end_frame_gt\"][:, :, 2] == 1.0] = 2.0\n",
    "plt.imshow(loaded_images[4][\"end_frame_gt\"][:,:,2])\n",
    "plt.subplot(1, 2, 2)  # Second subplot\n",
    "plt.imshow(loaded_images[4][\"end_frame\"][:,:,2])\n",
    "# for i in range(len(loaded_images[4][\"end_frame_gt\"][:,:,0])):\n",
    "#     for row in loaded_images[4][\"end_frame_gt\"][:,:,0][i]:\n",
    "#         if np.any(loaded_images[4][\"end_frame_gt\"][:,:,0][i] != 0):\n",
    "#             print(loaded_images[4][\"end_frame_gt\"][:,:,0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels List: [0.0, 1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "unique_labels_set = set()\n",
    "\n",
    "for nifti_img in loaded_images:\n",
    "\n",
    "    # Find unique labels in the current image and add them to the set\n",
    "    unique_labels_set.update(np.unique(nifti_img[\"start_frame_gt\"]))\n",
    "\n",
    "# Convert the set of unique labels to a sorted list\n",
    "unique_labels_list = sorted(list(unique_labels_set))\n",
    "\n",
    "# Print the list of unique labels across all loaded images\n",
    "print(\"Unique Labels List:\", unique_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(loaded_images))\n",
    "# print(type(loaded_images))\n",
    "# # print(loaded_images.index(\"???\"))\n",
    "# print(len(loaded_images[0]))\n",
    "# print(type(loaded_images[0]))\n",
    "# print(loaded_images[0].keys())\n",
    "# print(loaded_images[0].items())\n",
    "# print(loaded_images[0].values())\n",
    "# loaded_images[0]\n",
    "# print(type(loaded_images[0][\"start_frame\"]))\n",
    "# for i in loaded_images:\n",
    "#     for j in i.values():\n",
    "#         print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (216, 256, 9): Count 56\n",
      "Shape (216, 256, 10): Count 44\n",
      "Shape (216, 256, 8): Count 44\n",
      "Shape (256, 216, 10): Count 36\n",
      "Shape (256, 216, 9): Count 28\n",
      "...\n",
      "Shape (174, 208, 16): Count 4\n",
      "Shape (174, 208, 20): Count 4\n",
      "Shape (232, 288, 15): Count 4\n",
      "Shape (192, 256, 8): Count 4\n",
      "Shape (214, 256, 10): Count 4\n",
      "Total count of different shapes: 600\n",
      "\n",
      "Minimum values for each dimension: [154, 154, 6]\n",
      "\n",
      "Dimension 1: Mode 256, Min 154, Max 428, Range 274\n",
      "Dimension 2: Mode 256, Min 154, Max 512, Range 358\n",
      "Dimension 3: Mode 10, Min 6, Max 21, Range 15\n",
      "\n",
      "Total sum of values in the 3rd dimension (z): 778\n"
     ]
    }
   ],
   "source": [
    "def run_stats(loaded_images):\n",
    "    if isinstance(loaded_images[0], dict):\n",
    "        shape_counts = {}\n",
    "        for d in loaded_images:\n",
    "            for key, value in d.items():\n",
    "                if isinstance(value, np.ndarray) and value.ndim == 3:\n",
    "                    shape = value.shape\n",
    "                    # Use the shape as a key in the dictionary and increment the count\n",
    "                    shape_counts[shape] = shape_counts.get(shape, 0) + 1\n",
    "\n",
    "        # Sort shapes by count in descending order\n",
    "        sorted_shapes = sorted(shape_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for shape, count in sorted_shapes[:5]:\n",
    "            print(f\"Shape {shape}: Count {count}\")\n",
    "        print(\"...\")\n",
    "        for shape, count in sorted_shapes[-5:]:\n",
    "            print(f\"Shape {shape}: Count {count}\")\n",
    "\n",
    "        total_count = sum(count for _, count in sorted_shapes)\n",
    "        print(f\"Total count of different shapes: {total_count}\\n\")\n",
    "\n",
    "        min_values = []\n",
    "        for dim in range(len(sorted_shapes[0][0])):\n",
    "            min_value = min(shape[dim] for shape, _ in sorted_shapes)\n",
    "            min_values.append(min_value)\n",
    "        print(f\"Minimum values for each dimension: {min_values}\\n\")\n",
    "\n",
    "        for dim in range(len(sorted_shapes[0][0])):\n",
    "            dimension_values = [shape[dim] for shape, _ in sorted_shapes]\n",
    "            mode_value = statistics.mode(dimension_values)\n",
    "            range_value = max(dimension_values) - min(dimension_values)\n",
    "            print(f\"Dimension {dim + 1}: Mode {mode_value}, Min {min(dimension_values)}, Max {max(dimension_values)}, Range {range_value}\")\n",
    "        total_sum_third_dim = sum(shape[2] for shape, _ in sorted_shapes)\n",
    "        print(f\"\\nTotal sum of values in the 3rd dimension (z): {total_sum_third_dim}\")\n",
    "        \n",
    "    elif isinstance(loaded_images[0], np.ndarray):\n",
    "        shape_counts = {}\n",
    "        for d in loaded_images:\n",
    "            if isinstance(d, np.ndarray) and d.ndim == 3:\n",
    "                shape = d.shape\n",
    "                shape_counts[shape] = shape_counts.get(shape, 0) + 1\n",
    "\n",
    "        sorted_shapes = sorted(shape_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for shape, count in sorted_shapes:\n",
    "            print(f\"Shape {shape}: Count {count}\")\n",
    "\n",
    "        total_count = sum(count for _, count in sorted_shapes)\n",
    "        print(f\"Total count of different shapes: {total_count}\\n\")\n",
    "\n",
    "        print(f'Sorted shapes: {sorted_shapes}')\n",
    "        # min_values = []\n",
    "        # for dim in range(len(sorted_shapes)):\n",
    "        #     min_value = min(shape[dim] for shape in sorted_shapes)\n",
    "        #     min_values.append(min_value)\n",
    "        # print(f\"Minimum values for each dimension: {min_values}\\n\")\n",
    "\n",
    "        # for dim in range(len(sorted_shapes)):\n",
    "        #     dimension_values = [shape[dim] for shape in sorted_shapes]\n",
    "        #     mode_value = statistics.mode(dimension_values)\n",
    "        #     range_value = max(dimension_values) - min(dimension_values)\n",
    "        #     print(f\"Dimension {dim + 1}: Mode {mode_value}, Min {min(dimension_values)}, Max {max(dimension_values)}, Range {range_value}\")\n",
    "        \n",
    "        # total_sum_third_dim = sum(shape[2] for shape, _ in sorted_shapes)\n",
    "        # print(f\"\\nTotal sum of values in the 3rd dimension (z): {total_sum_third_dim}\")\n",
    "\n",
    "run_stats(loaded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorient + resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(loaded_images[0][\"start_frame\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorient\n",
    "\n",
    "desired_orientation = nib.orientations.axcodes2ornt(('R', 'A', 'S'))\n",
    "# for image_dict in loaded_images:\n",
    "#     for key, image_data in image_dict.items():\n",
    "#         img = nib.Nifti1Image(image_data, affine=np.eye(4))\n",
    "#         original_orientation = nib.orientations.axcodes2ornt(img.affine)\n",
    "        \n",
    "#         if not nib.orientations.ornt_eq(original_orientation, desired_orientation):\n",
    "#             # Transform the image to the desired orientation\n",
    "#             img = nib.orientations.apply_orientation(img, nib.orientations.ornt_transform(original_orientation, desired_orientation))\n",
    "            \n",
    "#             # Update the dictionary with the reoriented ndarray\n",
    "#             image_dict[key] = img.get_fdata()\n",
    "\n",
    "unique_orientations = set()\n",
    "for image_dict in loaded_images:\n",
    "    # Loop through the keys in each dictionary (image1, image2, image3, image4)\n",
    "    for key, image_data in image_dict.items():\n",
    "        # Create a temporary NIfTI image from the ndarray\n",
    "        img = nib.Nifti1Image(image_data, affine=np.eye(4))\n",
    "        \n",
    "        # Get the orientation codes from the affine matrix\n",
    "        orientation = nib.orientations.aff2axcodes(img.affine)\n",
    "        \n",
    "        # Add the orientation to the set to keep only unique orientations\n",
    "        unique_orientations.add(tuple(orientation))\n",
    "\n",
    "# Convert the unique orientations back to lists for readability, if needed\n",
    "unique_orientations = [list(o) for o in unique_orientations]\n",
    "\n",
    "# Now, unique_orientations contains a list of all unique orientations in the input dictionaries\n",
    "print(unique_orientations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform every (x, y, z) voxel to \"z\" number of (x, y) images\n",
    "\n",
    "more_loaded_images = []\n",
    "for dict in loaded_images:\n",
    "    for key, value in dict.items():\n",
    "        shape = value.shape\n",
    "        modified_dict = {}\n",
    "        \n",
    "        for k in range(shape[2]):\n",
    "            sliced_array = value[:, :, k]\n",
    "            modified_dict[f'array_{k+1}'] = sliced_array\n",
    "        \n",
    "        more_loaded_images.append({key: modified_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'numpy.ndarray'>\n",
      "(216, 256)\n"
     ]
    }
   ],
   "source": [
    "print(len(more_loaded_images))\n",
    "print(type(more_loaded_images))\n",
    "print(type(more_loaded_images[0]))\n",
    "print(type(more_loaded_images[0][\"start_frame\"]))\n",
    "print(type(more_loaded_images[0][\"start_frame\"][\"array_1\"]))\n",
    "print(more_loaded_images[0][\"start_frame\"][\"array_1\"].shape)\n",
    "# print(more_loaded_images[0][\"start_frame_gt\"][\"array_1\"]) #error - még nem jó a struktúra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hajni:\n",
    "\n",
    "#resize images\n",
    "loaded_images_resized = []\n",
    "for i in range(len(loaded_images)):\n",
    "    for j in loaded_images[i].values():\n",
    "        loaded_images_resized.append(skTrans.resize(j, (256,256,1), order=1, preserve_range=False, anti_aliasing=True))\n",
    "\n",
    "# squeeze to 2d\n",
    "for i in range(len(loaded_images_resized)):\n",
    "    loaded_images_resized[i] = np.squeeze(loaded_images_resized[i], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "600\n",
      "Total count of different shapes: 0\n",
      "\n",
      "Sorted shapes: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(loaded_images_resized))\n",
    "print(len(loaded_images_resized))\n",
    "run_stats(loaded_images_resized)\n",
    "loaded_images_resized[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[ 1., -1.,  2.],[ 2.,  0.,  0.],[ 0.,  1., -1.]])\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "[[ 1. -1.  2.]\n",
      " [ 2.  0.  0.]\n",
      " [ 0.  1. -1.]]\n",
      "[1.         0.         0.33333333]\n",
      "[0.81649658 0.81649658 1.24721913]\n",
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n",
      "[0. 0. 0.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(scaler)\n",
    "\n",
    "print(X_train)\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)\n",
    "\n",
    "print(X_scaled)\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  2.]\n",
      " [ 2.  0.  0.]\n",
      " [ 0.  1. -1.]]\n",
      "[[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "print(X_train)\n",
    "print(X_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  2.]\n",
      " [ 2.  0.  0.]\n",
      " [ 0.  1. -1.]]\n",
      "[[ 0.40824829 -0.40824829  0.81649658]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.70710678 -0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "X_normalized = preprocessing.normalize(X_train, norm='l2')\n",
    "\n",
    "print(X_train)\n",
    "print(X_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install reorient-nii\n",
    "\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorienting + resizing\n",
    "\n",
    "# noise removal + smoothing\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "img = nib.load('path/to/your/image.nii')\n",
    "img_data = img.get_fdata()\n",
    "smoothed_img_data = gaussian_filter(img_data, sigma=1.0)\n",
    "smoothed_img = nib.Nifti1Image(smoothed_img_data, affine=img.affine)\n",
    "nib.save(smoothed_img, 'path/to/save/smoothed_image.nii')\n",
    "\n",
    "\n",
    "# normalizing + standardizing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "img = nib.load('path/to/your/image.nii')\n",
    "img_data = img.get_fdata()\n",
    "scaler = MinMaxScaler()\n",
    "normalized_img_data = scaler.fit_transform(img_data.reshape(-1, 1)).reshape(img_data.shape)\n",
    "normalized_img = nib.Nifti1Image(normalized_img_data, affine=img.affine)\n",
    "nib.save(normalized_img, 'path/to/save/normalized_image.nii')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nibabel as nib\n",
    "\n",
    "img = nib.load('path/to/your/image.nii')\n",
    "img_data = img.get_fdata()\n",
    "# Reshape the data to (num_samples, num_features)\n",
    "img_data_flat = img_data.reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(img_data_flat).reshape(img_data.shape)\n",
    "standardized_img = nib.Nifti1Image(standardized_data, affine=img.affine)\n",
    "nib.save(standardized_img, 'path/to/save/standardized_image.nii')\n",
    "\n",
    "# adjusting brightness + adjusting contrast + adjusting sharpness\n",
    "\n",
    "# thresholding\n",
    "\n",
    "# resampling\n",
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "img = nib.load('path/to/your/image.nii')\n",
    "target_voxel_size = (1.0, 1.0, 1.0)\n",
    "\n",
    "resampling_factor = (img.header.get_zooms()[0] / target_voxel_size[0],\n",
    "                     img.header.get_zooms()[1] / target_voxel_size[1],\n",
    "                     img.header.get_zooms()[2] / target_voxel_size[2])\n",
    "\n",
    "resampled_img_data = zoom(img.get_fdata(), resampling_factor, order=3)  # order=3 for cubic interpolation\n",
    "resampled_img = nib.Nifti1Image(resampled_img_data, affine=None)\n",
    "nib.save(resampled_img, 'path/to/save/resampled_image.nii')\n",
    "\n",
    "\n",
    "# data augmentation\n",
    "#pip install tensorflow\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import numpy as np\n",
    "# import nibabel as nib\n",
    "\n",
    "# img = nib.load('path/to/your/image.nii')\n",
    "# img_data = img.get_fdata()\n",
    "# img_data = np.expand_dims(img_data, axis=-1)\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# augmented_data = []\n",
    "# for batch in datagen.flow(np.expand_dims(img_data, axis=0), batch_size=1):\n",
    "#     augmented_data.append(batch[0, :, :, :, 0])\n",
    "#     if len(augmented_data) >= 10:  # Generate 10 augmented samples\n",
    "#         break\n",
    "\n",
    "# for i, augmented_img_data in enumerate(augmented_data):\n",
    "#     augmented_img = nib.Nifti1Image(augmented_img_data, affine=img.affine)\n",
    "#     nib.save(augmented_img, f'path/to/save/augmented_image_{i}.nii')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps, Image, ImageFilter, ImageDraw\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#img = Image.fromarray(loaded_images[1][\"start_frame\"][:, :, 1].astype(np.uint8))\n",
    "#img.show()\n",
    "\n",
    "img = loaded_images[1][\"start_frame\"][:, :, 1].astype(np.uint8)\n",
    "img = (img - np.min(img)) / (np.max(img) - np.min(img)) * 1\n",
    "cv2.imshow('Processed Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\BME\\MSc\\dl-project\\preprocessing.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BME/MSc/dl-project/preprocessing.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             plt\u001b[39m.\u001b[39mtitle(titles[j])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/BME/MSc/dl-project/preprocessing.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/BME/MSc/dl-project/preprocessing.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plot_images(loaded_images[:\u001b[39m10\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_images' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_images(loaded_images):\n",
    "    titles = ['start_frame', 'start_frame_gt', 'end_frame', 'end_frame_gt']\n",
    "\n",
    "    for i in range(len(loaded_images)):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.suptitle(f'Patient {i+1}')\n",
    "\n",
    "        for j in range(4):\n",
    "            plt.subplot(2, 2, j + 1)\n",
    "            plt.imshow(loaded_images[i][titles[j]][:, :, 1], cmap='gray')\n",
    "            plt.title(titles[j])\n",
    "            plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_images(loaded_images[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
